---
project:
  title: "Lab 6: Machine Learning in Hydrology"
  subtitle: ESS330
  output-dir: docs
  type: website
  author:
    - name: Grace Rinehart
      email: mailto:gracerin@colostate.edu
format: 
  html:
    self-contained: true
editor: visual
---

# Question 1

```{r}
library(tidyverse)
library(tidymodels)
library(powerjoin)
library(glue)
library(vip)
library(baguette)
library(ggthemes)
library(patchwork)
library(xgboost)
library(yardstick)

root  <- 'https://gdex.ucar.edu/dataset/camels/file'

download.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf', 
              'data/camels_attributes_v2.0.pdf')

types <- c("clim", "geol", "soil", "topo", "vege", "hydro")

remote_files  <- glue('{root}/camels_{types}.txt')
local_files   <- glue('data/camels_{types}.txt')

walk2(remote_files, local_files, download.file, quiet = TRUE)

camels <- map(local_files, read_delim, show_col_types = FALSE) 

camels <- power_full_join(camels ,by = 'gauge_id')

# zero_q_freq represents frequency of days with Q = 0 mm/day, and it's measured as a percent.
```

# Question 2
```{r}
plot1 <- ggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) +
  borders("state", colour = "gray50") +
  geom_point(aes(color = aridity)) +
  scale_color_gradient(low = "lightblue", high = "darkgreen") +
  labs(title= "Sites Ranked on Aridity", x= "Gauge Longitude", y= "Gauge Latitude" ) +
  ggthemes::theme_map() 

plot2 <- ggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) +
  borders("state", colour = "gray50") +
  geom_point(aes(color = p_mean)) +
  scale_color_gradient(low = "slategray1", high = "orchid4") +
  labs(title= "Sites Ranked on Mean Daily Precipitation", x= "Gauge Longitude", y= "Gauge Latitude" ) +
  ggthemes::theme_map()

plot1 + plot2
```

# Question 3

```{r}
camels %>%
  select(aridity, p_mean, q_mean) %>% 
  drop_na() %>%
  cor()

set.seed(123)
camels <- camels %>%
  mutate(logQmean = log(q_mean))

camels_split <- initial_split(camels, prop = 0.8)
camels_train <- training(camels_split)
camels_test  <- testing(camels_split)

camels_cv <- vfold_cv(camels_train, v = 10)

rec <-  recipe(logQmean ~ aridity + p_mean, data = camels_train) %>%
  step_log(all_predictors()) %>%
  step_interact(terms = ~ aridity:p_mean) %>%
  step_naomit(all_predictors(), all_outcomes())

lm_model <- linear_reg() %>%
  set_engine("lm") %>%
  set_mode("regression")

rf_model <- rand_forest() %>%
  set_engine("ranger")%>%
  set_mode("regression")

xgb_model <- boost_tree() %>%
  set_engine("xgboost") %>%
  set_mode("regression")

nn_model <- bag_mlp() %>%
  set_engine("nnet") %>%
  set_mode("regression")

lm_wf <- workflow() %>%
  add_recipe(rec) %>%
  add_model(lm_model) %>%
  fit(data = camels_train) 

rf_wf <- workflow() %>%
  add_recipe(rec) %>%
  add_model(rf_model) %>%
  fit(data = camels_train) 

xgb_wf <- workflow() %>%
  add_recipe(rec) %>%
  add_model(xgb_model) %>%
  fit(data = camels_train)

nn_wf <- workflow() %>%
  add_recipe(rec) %>%
  add_model(nn_model) %>%
  fit(data = camels_train)

lm_data <- augment(lm_wf, new_data = camels_test)
rf_data <- augment(rf_wf, new_data = camels_test)
xgb_data <- augment(xgb_wf, new_data = camels_test)
nn_data <- augment(nn_wf, new_data = camels_test)

metrics(lm_data,  truth = logQmean, estimate = .pred)
metrics(rf_data,  truth = logQmean, estimate = .pred)
metrics(xgb_data,  truth = logQmean, estimate = .pred)
metrics(nn_data,  truth = logQmean, estimate = .pred)

# I would move forward with the neutral network model. The root mean squared error (RMSE) and mean absolute error (MAE) values are lower than the other models. The R squared value (RSQ) is also closer to 1. These values show that the neutral network model is more accurate than the other 3 models.
```

# Question 4a: Data Splitting

```{r}
set.seed(123)

camels_split <- initial_split(camels, prop = 0.75)
camels_train <- training(camels_split)
camels_test  <- testing(camels_split)

camels_cv <- vfold_cv(camels_train, v = 10)
```

# Question 4b: Recipe

```{r}
camels <- camels %>%
  mutate(logQmean = log(q_mean))

# I chose this formula because it is straightforward and allows for the normalization of the skewed q_mean data. This formula also works well with regression models.

recip <-  recipe(logQmean ~ aridity + p_mean, data = camels_train) %>%
  step_log(all_predictors()) %>%
  step_interact(terms = ~ aridity:p_mean) %>%
  step_naomit(all_predictors(), all_outcomes())
```

# Question 4c: Defining Models

```{r}
rand_forest_model <- rand_forest() %>%
  set_engine("ranger") %>%
  set_mode("regression")

xgboost_model <- boost_tree() %>%
  set_engine("xgboost") %>%
  set_mode("regression")

linear_model <- linear_reg() %>%
  set_engine("lm") %>%
  set_mode("regression")
```

# Question 4d: Workflow Set

```{r}
work_set <- workflow_set(list(recip), list(rand_forest_model, xgboost_model, linear_model)) %>%
  workflow_map('fit_resamples', resamples = camels_cv)
```

# Question 4e: Evaluation

```{r}
autoplot(work_set)

rank_results(work_set, rank_metric = "rsq", select_best = TRUE)

# I think the rand_forest model is the best of three models I chose. The root mean squared error (RMSE) is lower than the other models, and the R squared value (RSQ) is closer to 1. While all of the models had very similar results, the rand_forest model has more ideal values associated with it.
```

# Question 4f: Extract & Evaluate

```{r}
set.seed(123)

camels_split <- initial_split(camels, prop = 0.75)
camels_train <- training(camels_split)
camels_test  <- testing(camels_split)

rec <-  recipe(logQmean ~ aridity + p_mean, data = camels_train) %>%
  step_log(all_predictors()) %>%
  step_interact(terms = ~ aridity:p_mean) %>%
  step_naomit(all_predictors(), all_outcomes())

nn_model <- bag_mlp() %>%
  set_engine("nnet") %>%
  set_mode("regression")

nn_wf <- workflow() %>%
  add_recipe(rec) %>%
  add_model(nn_model) %>%
  fit(data = camels_train)

nn_data <- augment(nn_wf, new_data = camels_test)

plot <- ggplot(nn_data, aes(x = logQmean, y = .pred, colour = aridity)) +
  scale_color_gradient(low = "#FFFFC5", high = "red4") +
  geom_point() +
  geom_abline() +
  labs(title = "Observed vs Predicted Values", x = "Observed Values", y = "Predicted Values") +
  theme_linedraw()

print(plot)

# Most points are clustered near the black line, suggesting that the model generally performs well. While many points are close to the line, there is some noticeable deviation, especially in lower observed values on the left. Some points fall far below or far above the line, indicating that the model underestimates and overestimates certain values.
```
